#!/usr/bin/env python3
'''
Optune measure driver for SignalFx.  (C) 2018, Opsani.

use:
measure --info
measure --describe <app_id>
measure <app_id> < <measure-stdin-file.json>

This driver requires a YAML configuration file placed at a fixed location (see
CFG_FPATH constant).  See README.md for details.  Example config:

sfx:
    flow_program:     <val>     # REQUIRED:  SignalFlow program to query metrics
    flow_immediate:   <val>     # optional:  boolean, default False
    flow_resolution:  <val>     # optional:  integer ms, default None
    stream_endpoint:  <val>     # optional:  SignalFx stream API endpoint,
                                #            default https://stream.signalfx.com
    time_aggr:        <val>     # optional:  aggr method for space aggregates
                                #            default 'avg'
    space_aggr:       <val>     # optional:  aggr method for values at give time
                                #            default 'avg'
    pre_cmd_async:    <val>     # optional:  async bash cmd to run before warmup
    pre_cmd:          <val>     # optional:  bash cmd to run before warmup
    post_cmd:         <val>     # optional:  bash cmd to run after measure
'''

import os
import signal
import subprocess
import sys
import time
import yaml

import signalfx

from measure import Measure, ST_FAILED

DESC                 = 'SignalFx measure driver for Opsani Optune'
VERSION              = '1.0.0'
HAS_CANCEL           = True
PROGRESS_INTERVAL    = 30
CFG_FPATH            = './config.yaml'

DFLT_WARMUP          = 0
DFLT_DURATION        = 120
DFLT_TIME_AGGR       = 'avg'
DFLT_SPACE_AGGR      = 'avg'
DFLT_STREAM_ENDPOINT = 'https://stream.signalfx.com'
DFLT_METRIC_NAME     = 'perf'
DFLT_METRIC_UNIT     = ''
DFLT_FLOW_IMMEDIATE  = False
DFLT_FLOW_RESOLUTION = None

AGGR_OPERATORS       = ('avg', 'max', 'min', 'sum')
API_KEY_FPATH        = '/etc/optune-sfx-auth/api_key'
API_KEY_ENV_VAR      = 'OPTUNE_SFX_API_KEY'

class SignalFx(Measure):

    # overwrites super
    def describe(self):

        # @@TBD:  support user specified metric name and units
        # self._parse_config()
        # return {
        #     self.cfg['metric_name']: {
        #         'unit': self.cfg['metric_unit'],
        #     }
        # }

        return {'perf': {}}

    # overwrites super
    def handle_cancel(self, signal, frame):
        err = 'Exiting due to signal: {}'.format(signal)
        self.print_measure_error(err, ST_FAILED)

        # terminate pre_cmd_async, if any
        if hasattr(self, 'proc_async'):
            os.killpg(os.getpgid(self.proc_async.pid), signal.SIGTERM)

        sys.exit(3)

    # overwrites super
    def measure(self):

        # parse and valcheck:  control configuration
        assert 'control' in self.input_data, 'Input data missing control configuration'
        control  = self.input_data['control']
        warmup   = int(control.get('warmup', DFLT_WARMUP))
        duration = int(control.get('duration', DFLT_DURATION))
        assert warmup >= 0 and duration >= 0, \
            'Both warmup {} and duration {} must be non-negative'.format(warmup, duration)
        self.t_sleep = warmup + duration

        # parse and valcheck:  driver config
        self._parse_config()

        # query sfx:  verify signalflow program is valid
        self._init_sfx()
        qval = self._query_sfx_metric(self.cfg['flow_program'],
            self.cfg['flow_immediate'], self.cfg['flow_resolution'],
            self.cfg['time_aggr'], self.cfg['space_aggr'], duration)
        self.debug('Initial value for query {}:  {}'.format(
            self.cfg['flow_program'], qval))

        # execute pre_cmd_async, if any
        if self.cfg['pre_cmd_async'] is not None:
            self.proc_async = self._run_command_async(self.cfg['pre_cmd_async'])

        # execute pre_cmd, if any
        if self.cfg['pre_cmd'] is not None:
            self._run_command(self.cfg['pre_cmd'], pre=True)

        # sleep
        self.debug('Sleeping for {:d} seconds ({:d} warmup + {:d} duration)'.format(
            self.t_sleep, warmup, duration))
        time.sleep(self.t_sleep)

        # query sfx:  measure
        qval = self._query_sfx_metric(self.cfg['flow_program'],
            self.cfg['flow_immediate'], self.cfg['flow_resolution'],
            self.cfg['time_aggr'], self.cfg['space_aggr'], duration)

        # execute post_cmd, if any
        if self.cfg['post_cmd'] is not None:
            self._run_command(self.cfg['post_cmd'], pre=False)

        # terminate pre_cmd_async, if any
        if hasattr(self, 'proc_async'):
            os.killpg(os.getpgid(self.proc_async.pid), signal.SIGTERM)

        # construct result:  use computed value for perf metric
        # @@TBD:  use metric_name and metric_unit when describe supports this
        metrics = {
            'perf': {
                'value': qval,
                'annotation': self.cfg['flow_program'],
            }
        }
        annotations = {}

        return metrics, annotations

    # overwrites super:  update progress before printing it
    def print_progress(
            self,
            message=None,
            msg_index=None,
            stage=None,
            stageprogress=None):

        # update progress based on how much time has elapsed
        if hasattr(self, 't_sleep'):
            t_taken = time.time() - self.t_measure_start
            self.progress = int(min(100.0, 100.0*((t_taken)/self.t_sleep)))
            super().print_progress(message, msg_index, stage, stageprogress)

    # helper:  initialize sfx api module
    def _init_sfx(self):

        # as required:  read sfx_api_key from file (e.g., from k8s secret volume
        # mounted file) or from env variable
        if not hasattr(self, 'sfx_api_key'):
            if os.path.isfile(API_KEY_FPATH):
                with open(API_KEY_FPATH, 'r') as f:
                    self.sfx_api_key = f.read().rstrip()
            elif os.getenv(API_KEY_ENV_VAR, None) is not None:
                self.sfx_api_key = os.getenv(API_KEY_ENV_VAR)
            else:
                raise Exception('SignalFx API key does not exist either as the ' +
                    'file {} or as the env variable {}'.format(API_KEY_FPATH,
                    API_KEY_ENV_VAR))

        # initialize sfx api module
        try:
            self.sfx = signalfx.SignalFx(stream_endpoint=self.cfg['stream_endpoint'])
        except Exception as e:
            raise Exception(
                'Failed to initialize SignalFx API module. Error: {}'.format(str(e)))

    # helper:  query sfx metrics over last duration seconds and return
    # value computed from aggregating in time and space
    def _query_sfx_metric(self, program, immediate, resolution, time_aggr,
        space_aggr, duration):

        space_aggr_vals = []
        with self.sfx.signalflow(self.sfx_api_key) as flow:

            # execute SignalFlow program, obtaining a stream object:
            now_ms = int(time.time()) * 1000
            start_ms = now_ms - (duration * 1000)
            try:
                computation = flow.execute(program, start=start_ms, stop=now_ms,
                    immediate=immediate, resolution=resolution)
            except Exception as e:
                raise Exception(
                    'Failed to query SignalFx for program {}. Error: {}'.format(
                    program, str(e)))

            # process messages in computation stream
            for msg in computation.stream():
                if isinstance(msg, signalfx.signalflow.messages.DataMessage):
                    space_vals = list(msg.data.values())
                    assert len(space_vals) > 0, \
                        'SignalFx query for program {} returned empty data {}'.format(
                        program, msg.data)
                    space_aggr_vals.append(self._aggregate_values(space_vals,
                        space_aggr))

        # aggregate in time and return value
        assert len(space_aggr_vals) > 0, \
            'SignalFx query for program {} returned no data messages'
        return self._aggregate_values(space_aggr_vals, time_aggr)

    # helper:  return an aggregate value computed from an input list of values
    def _aggregate_values(self, vals, aggr):
        if aggr == 'avg':
            return sum(vals) / float(len(vals))
        if aggr == 'max':
            return max(vals)
        if aggr == 'min':
            return min(vals)
        if aggr == 'sum':
            return sum(vals)
        raise Exception('Unexpected aggregation method {}'.format(aggr))

    # helper:  run a Bash shell command and raise an Exception on failure
    # note:  if cmd is a string, this supports shell pipes, environment variable
    # expansion, etc.  The burden of safety is entirely on the user.
    def _run_command(self, cmd, pre=True):
        cmd_type = 'Pre-command' if pre else 'Post-command'
        res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            shell=True, executable='/bin/bash')
        msg = "cmd '{}', exit code {}, stdout {}, stderr {}".format(cmd,
            res.returncode, res.stdout, res.stderr)
        assert res.returncode == 0, '{} failed:  {}'.format(cmd_type, msg)
        self.debug('{}:  {}'.format(cmd_type, msg))

    # helper:  run a Bash shell command with stdout/stderr directed to /dev/null
    # and return the popen object
    def _run_command_async(self, cmd):
        proc = subprocess.Popen(cmd, stdin=subprocess.DEVNULL, stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL, shell=True, executable='/bin/bash',
            preexec_fn=os.setpgrp)
        self.debug('Pre-command async:  {}'.format(cmd))
        return proc

    # helper:  parse driver configuration from config file
    def _parse_config(self):

        # load YAML config file (raise any unhandled exception)
        try:
            fo = open(CFG_FPATH)
            desc = yaml.load(fo)
        except IOError as e:
            raise Exception('Cannot read configuration from {}:  {}'.format(
                CFG_FPATH, e.strerror))
        except yaml.error.YAMLError as e:
            raise Exception('Syntax error in {}:  {}'.format(CFG_FPATH, str(e)))
        fo.close()

        # parse descriptor
        sfx = desc.get('sfx')
        assert isinstance(sfx, dict), 'No sfx config in {}'.format(CFG_FPATH)
        assert 'flow_program' in sfx, 'No flow_program config in {}'.format(CFG_FPATH)
        self.cfg = {}
        self.cfg['flow_program']    = sfx['flow_program']
        self.cfg['flow_immediate']  = sfx.get('flow_immediate', DFLT_FLOW_IMMEDIATE)
        self.cfg['flow_resolution'] = sfx.get('flow_resolution', DFLT_FLOW_RESOLUTION)
        self.cfg['time_aggr']       = sfx.get('time_aggr', DFLT_TIME_AGGR)
        self.cfg['space_aggr']      = sfx.get('space_aggr', DFLT_SPACE_AGGR)
        self.cfg['stream_endpoint'] = sfx.get('stream_endpoint', DFLT_STREAM_ENDPOINT)
        #self.cfg['metric_name']     = sfx.get('metric_name', DFLT_METRIC_NAME)
        #self.cfg['metric_unit']     = sfx.get('metric_unit', DFLT_METRIC_UNIT)
        self.cfg['pre_cmd_async']   = sfx.get('pre_cmd_async')
        self.cfg['pre_cmd']         = sfx.get('pre_cmd')
        self.cfg['post_cmd']        = sfx.get('post_cmd')
        assert self.cfg['time_aggr'] in AGGR_OPERATORS, \
            'Unknown time_aggr {}'.format(time_aggr)
        assert self.cfg['space_aggr'] in AGGR_OPERATORS, \
            'Unknown space_aggr {}'.format(space_aggr)


if __name__ == '__main__':
    sfx = SignalFx(VERSION, DESC, HAS_CANCEL, PROGRESS_INTERVAL)
    sfx.run()
